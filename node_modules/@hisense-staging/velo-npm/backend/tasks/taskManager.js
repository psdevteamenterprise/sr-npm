const { withDuration } = require('../../public/performance/duration'); //relative path to needed file,  so we won't break site due to frontend modules imports inside backend

const { TASK_STATUS, CRON_JOB_MAX_DURATION_SEC } = require('./consts');
const { scheduleChildTasksAndUpdateParent } = require('./parentChildTasks/handler');
const {
  getTaskConfig,
  markTask,
  insertNewTask,
  getScheduledTasks,
  isParentTask,
  getTasksToProcess,
  bulkInsertTasks,
} = require('./utils');

function taskManager() {
  const processTask = (task, tasksConfig) =>
    withDuration(
      'processTask',
      async () => {
        const taskName = task.name;
        const didFailBefore = task.status === TASK_STATUS.FAILED;
        try {
          console.log(`[processTask] for ${taskName} Started`);
          const taskConfig = getTaskConfig(taskName, tasksConfig);
          await markTask({ task, status: TASK_STATUS.IN_PROGRESS });
          if (isParentTask(task, taskConfig)) {
            await scheduleChildTasksAndUpdateParent(task, tasksConfig);
            //TODO: handle collecting children outputs and use it, e.g csv generation
            return task; // we return here, as we let upper line handle parent task status update;
          }
          const identifier = await taskConfig.getIdentifier(task);
          if (taskConfig.shouldSkipCheck(identifier)) {
            console.log(`[${taskName}] Task for identifier ${identifier} will be skipped`);
            await markTask({
              task,
              status: TASK_STATUS.SKIPPED,
              error: `${taskName} skipped`,
            });
            console.log(`[${taskName}] Task for identifier ${identifier} is skipped`);
            return task;
          }

          const result = await taskConfig.process(identifier);
          //setting the processing output to the task data, so it can be used by the parent task if needed
          task.data.output = result;
          await markTask({ task, status: TASK_STATUS.SUCCESS });
          console.log(
            `[processTask] for ${taskName} Task with identifier ${identifier} completed successfully`
          );
          return task;
        } catch (error) {
          const errMsg = `[processTask] for ${taskName} Task failed with error: ${error}`;
          console.error(errMsg);
          const amountOfRetries = didFailBefore ? task.amountOfRetries + 1 : task.amountOfRetries; // this is the first time it fails
          await markTask({
            task,
            error,
            status: TASK_STATUS.FAILED,
            amountOfRetries,
          });
          throw new Error(errMsg);
        }
      },
      console
    );
  /**
   * @description Processing tasks based on how many the cron job tick can handle and running them sequentially to be as safe as possible
   * */
  const processTasksBasedOnVeloLimit = async (scheduledTasks, tasksConfig) => {
    console.log(`processTasksBasedOnVeloLimit: ${ JSON.stringify(scheduledTasks) } ${ JSON.stringify(tasksConfig) }`);
    const toProcessTasks = getTasksToProcess({
      scheduledTasks,
      tasksConfig,
      maxDuration: CRON_JOB_MAX_DURATION_SEC,
    });
    console.log(`processTasksBasedOnVeloLimit: toProcessTasks: ${ JSON.stringify(toProcessTasks) }`);
    console.log(
      `[processTasksBasedOnVeloLimit] started processing: ${toProcessTasks.length} tasks`
    );
    for (const task of toProcessTasks) {
      // want to run tasks sequentially, but still don't want if one fails to stop others from running to gain the most from each job tick
      try {
        await processTask(task, tasksConfig);
      } catch (error) {
        console.error(
          `[processTasksBasedOnVeloLimit] failed to process task ${JSON.stringify(
            task
          )} with error: ${error}`
        );
      }
    }
    console.log(
      `[processTasksBasedOnVeloLimit] finished processing: ${toProcessTasks.length} tasks`
    );
  };
  const runScheduledTasks = async tasksConfig => {
    try {
      const scheduledTasks = await getScheduledTasks();
      console.log(`runScheduledTasks: scheduledTasks: ${ JSON.stringify(scheduledTasks) }`);
      console.log(`runScheduledTasks: tasksConfig: ${ JSON.stringify(tasksConfig) }`);
      if (scheduledTasks.length) {
        await processTasksBasedOnVeloLimit(scheduledTasks, tasksConfig);
      } else {
        console.log(
          '[runScheduledTasks] No Tasks to process',
          JSON.stringify({ scheduledTasksCount: scheduledTasks.length })
        );
      }
    } catch (error) {
      console.error(`[runScheduledTasks] failed with error: ${error}`);
      throw error;
    }
  };

  return {
    schedule: insertNewTask,
    scheduleInBulk: bulkInsertTasks,
    processTask,
    runScheduledTasks: (...args) =>
      withDuration('runScheduledTasks', () => runScheduledTasks(...args), console),
  };
}

module.exports = { taskManager };
